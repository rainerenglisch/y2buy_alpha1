{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../../download/GoogleNews-vectors-negative300.bin', binary=True, limit=400000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'he' is to 'his' as 'she' is to 'her'\n",
      "'big' is to 'bigger' as 'bad' is to 'worse'\n",
      "'going' is to 'went' as 'being' is to 'were'\n"
     ]
    }
   ],
   "source": [
    "# \"boy\" is to \"father\" as \"girl\" is to ...?\n",
    "model.most_similar(['girl', 'father'], ['boy'], topn=3)\n",
    "[('mother', 0.61849487), ('wife', 0.57972813), ('daughter', 0.56296098)]\n",
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "    a, b, x = example.split()\n",
    "    predicted = model.most_similar([x, b], [a])[0][0]\n",
    "    print(\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))\n",
    "#'he' is to 'his' as 'she' is to 'her'\n",
    "#'big' is to 'bigger' as 'bad' is to 'worse'\n",
    "#'going' is to 'went' as 'being' is to 'was'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which word doesn't go with the others?\n",
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "#'cereal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "client = pymongo.MongoClient()\n",
    "mydb = client['y2buy_1']\n",
    "my_collection = mydb['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\_ not in wordvectors.\n",
      "moscow not in wordvectors.\n",
      "alibonus not in wordvectors.\n",
      "xiaomi not in wordvectors.\n",
      ".. not in wordvectors.\n",
      "aliexpress not in wordvectors.\n",
      "redmi not in wordvectors.\n",
      "petersburg not in wordvectors.\n",
      "telefonchik not in wordvectors.\n",
      "// not in wordvectors.\n",
      "megabonus not in wordvectors.\n",
      "krasnodar not in wordvectors.\n",
      "t. not in wordvectors.\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "features_vec = []\n",
    "for feature_doc in my_collection.find():\n",
    "    feature = feature_doc[\"feature\"]\n",
    "    try:\n",
    "        feature_vec = model.wv[feature] \n",
    "        features.append(feature)\n",
    "        features_vec.append(feature_vec)\n",
    "    except KeyError:\n",
    "        print(feature + \" not in wordvectors.\")\n",
    "#features= [feature_doc[\"feature\"]  for feature_doc in my_collection.find()]\n",
    "#feature_vec = [model.wv[feature] for feature in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_array = np.asarray(features_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "nc = 7\n",
    "kmeans = KMeans(n_clusters=nc, random_state=0).fit(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 0, 3, 2, 2, 3,\n",
       "       2, 1, 2, 2, 1, 1, 2, 6, 2, 1, 1, 1, 3, 2, 4, 2, 1, 2, 3, 1, 1, 3, 1,\n",
       "       2, 2, 2, 1, 2, 5, 1, 1, 2, 2, 1, 3, 1, 2, 4, 1, 1, 1, 6, 2, 1, 2, 2,\n",
       "       3, 2, 5, 2, 2, 2, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 0, 1, 1, 2, 1, 1, 2,\n",
       "       2, 1, 2, 2, 2, 1, 2, 5, 2, 2, 5, 2, 1, 3, 4, 1, 5, 2, 2, 6, 1, 1, 1,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 5, 1, 2, 2, 2, 1, 2, 1, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 1, 2, 6, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 1, 4, 2, 2, 1, 2, 2, 1, 2, 2, 1, 0, 2, 1, 1, 2, 2, 0], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['problem' 'thing' 'damage' 'difference' 'glitch' 'fault']\n",
      "['phone' 'seller' 'day' 'week' 'order' 'gift' 'description' 'case'\n",
      " 'purchase' 'mail' 'month' 'box' 'price' 'parcel' 'complaint' 'shipping'\n",
      " 'store' 'package' 'version' 'dispute' 'charge' 'extension' 'question'\n",
      " 'review' 'payment' 'condition' 'date' 'stock' 'card' 'bomb' 'refund' 'bag'\n",
      " 'number' 'year' 'check' 'telephone' 'amount' 'memory' 'fingerprint'\n",
      " 'speaker' 'fact' 'reference' 'button' 'book' 'sent' 'message' 'request'\n",
      " 'note' 'account' 'receipt' 'link' 'application' 'reason']\n",
      "['everything' 'delivery' 'work' 'film' 'time' 'thank' 'money' 'recommend'\n",
      " 'quality' 'glass' 'region' 'super' 'packaging' 'track' 'screen' 'product'\n",
      " 'custom' 'advise' 'thanks' 'use' 'post' 'fine' 'air' 'cover' 'way'\n",
      " 'outlet' 'excellent' 'hand' 'sound' 'fast' 'color' 'everyone' 'cool'\n",
      " 'service' 'nothing' 'match' 'come' 'communication' 'level' 'something'\n",
      " 'point' 'class' 'help' 'look' 'shop' 'unit' 'machine' 'fire' 'speed'\n",
      " 'course' 'buy' 'protection' 'cost' 'record' 'china' 'test' 'territory'\n",
      " 'edge' 'display' 'wrap' 'internet' 'commodity' 'standard' 'lot' 'fly'\n",
      " 'perfect' 'frame' 'respect' 'return' 'end' 'language' 'play' 'site' 'rule'\n",
      " 'communicate' 'model' 'fit' 'size' 'take' 'scratch' 'anything' 'see'\n",
      " 'body' 'function' 'regret' 'let' 'bumper' 'pay' 'brand' 'gold' 'operation'\n",
      " 'hope' 'ok' 'minus' 'game' 'performance' 'put' 'impression' 'bit' 'set']\n",
      "['firmware' 'adapter' 'battery' 'silicone' 'smartphone' 'device'\n",
      " 'headphone' 'charger' 'socket']\n",
      "['russia' 'singapore' 'le' 'ali' 'http']\n",
      "['star' 'wife' 'friend' 'dealer' 'son' 'husband']\n",
      "['camera' 'photo' 'picture' 'video']\n"
     ]
    }
   ],
   "source": [
    "for label in range(nc):\n",
    "    print(np.asarray(features)[kmeans.labels_ == label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
