{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import gzip \n",
    "#from StringIO import StringIO\n",
    "import urllib.request\n",
    "import requests, zipfile, io\n",
    "\n",
    "def parse(url): \n",
    "    \n",
    "    r = requests.get(url)\n",
    "    g = gzip.open(io.BytesIO(r.content))\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json \n",
    "import gzip \n",
    "def parse(url): \n",
    "    g = gzip.open(url, 'r') \n",
    "    for l in g: \n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "def myReviews(review_files_urls, catFilter = None, asin = None, concatenate = False):\n",
    "    preprocess_reviewText = []\n",
    "    for url in review_files_urls:\n",
    "        print(\"Processing url: \" + url)\n",
    "        review_item_iterator = iter(parse(url))\n",
    "        it = 0\n",
    "        conc_count = 0\n",
    "        for review_item in review_item_iterator:\n",
    "            it += 1\n",
    "        #for it in range(1000000):\n",
    "            if it%100000==0:\n",
    "                print(\"it=\"+str(it))\n",
    "\n",
    "            reviewText = review_item[\"reviewText\"]\n",
    "            label = review_item[\"asin\"] + \"_\" + review_item[\"reviewerID\"] \n",
    "            preprocess_reviewText_i = gensim.utils.simple_preprocess(reviewText)\n",
    "\n",
    "\n",
    "            #yield gensim.models.doc2vec.LabeledSentence(words=preprocess_reviewText, tags=[label])\n",
    "            if (catFilter == None or (catFilter in review_item[\"categories\"])) and (asin == None or (asin == review_item[\"asin\"])):\n",
    "                if concatenate==False:\n",
    "                    yield preprocess_reviewText_i\n",
    "                else:\n",
    "                    conc_count += 1\n",
    "                    preprocess_reviewText.extend(preprocess_reviewText_i)\n",
    "                    print(\"Concatenated count: \"+str(conc_count))\n",
    "    if concatenate == True:\n",
    "        print(\"Return the final text with length: \"+str(len(preprocess_reviewText)))\n",
    "        print(preprocess_reviewText)\n",
    "        yield preprocess_reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/\"\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "html = urllib.request.urlopen(base_url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "#print(soup.prettify())\n",
    "all_html_links = soup.find_all('a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for links in all_html_links:\n",
    "    if re.match(\"^review.*[^_5|_10].json.gz$\", links[\"href\"]):\n",
    "        print(links[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_file_names = [links[\"href\"] for links in all_html_links if re.match(\"^review.*[^_5|_10].json.gz$\", links[\"href\"])]\n",
    "#print(review_file_names)\n",
    "review_file_urls = [base_url + review_file_name for review_file_name in review_file_names]\n",
    "#print(review_file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing url: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_All_Beauty.json.gz\n",
      "Processing url: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_All_Credit_Cards.json.gz\n",
      "Processing url: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_All_Electronics.json.gz\n",
      "Processing url: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Alternative_Rock.json.gz\n",
      "Processing url: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Coins.json.gz\n",
      "Processing url: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Amazon_Fashion.json.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-429a9e5ae466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionaryFileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#dictionary = corpora.Dictionary(myReviews(\"Cell Phones\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyReviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_file_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0monce_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdocfreq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mister/Extension/anaconda3/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mister/Extension/anaconda3/lib/python3.6/site-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0munique\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;31m# log progress & run a regular check for pruning, once every 10k docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdocno\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-43547ffdce93>\u001b[0m in \u001b[0;36mmyReviews\u001b[0;34m(review_files_urls, catFilter, asin, concatenate)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mreviewText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reviewText\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"asin\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreview_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reviewerID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mpreprocess_reviewText_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviewText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mister/Extension/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36msimple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \"\"\"\n\u001b[1;32m    220\u001b[0m     tokens = [\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin_len\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     ]\n",
      "\u001b[0;32m/media/mister/Extension/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \"\"\"\n\u001b[1;32m    220\u001b[0m     tokens = [\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin_len\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     ]\n",
      "\u001b[0;32m/media/mister/Extension/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36msimple_tokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msimple_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPAT_ALPHABETIC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "import os\n",
    "dictionaryFileName = '../../download/word2vec/reviews_all.dict'\n",
    "if os.path.isfile(dictionaryFileName)==False:\n",
    "    #dictionary = corpora.Dictionary(myReviews(\"Cell Phones\"))\n",
    "    dictionary = corpora.Dictionary(myReviews(review_file_urls))\n",
    "    from six import iteritems\n",
    "    once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "    dictionary.filter_tokens(once_ids)  # remove stop words and words that appear only once\n",
    "    dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "    dictionary.save(dictionaryFileName)  # store the dictionary, for future reference\n",
    "else:\n",
    "    dictionary = corpora.Dictionary.load(dictionaryFileName)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myCorpus(review_file_urls, catFilter = None, asin = None, concatenate = False):\n",
    "    for review in myReviews(review_file_urls,catFilter,asin,concatenate):\n",
    "    # assume there's one document per line, tokens separated by whitespace\n",
    "        yield dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tfidfFileName ='../../download/word2vec/reviews_all_corpus.tfidf'\n",
    "if os.path.isfile(tfidfFileName)==False:\n",
    "    #tfidf = models.TfidfModel(myCorpus(\"Cell Phones\"))\n",
    "    tfidf = models.TfidfModel(myCorpus(review_file_urls))\n",
    "    tfidf.save(tfidfFileName)\n",
    "else:\n",
    "    tfidf = models.TfidfModel.load(tfidfFileName)\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tfidf_apple_5s_FileName ='../../download/word2vec/apple_5s_review.tfidf'\n",
    "if os.path.isfile(tfidf_apple_5s_FileName)==False:\n",
    "    apple_5s_corpus = next(myCorpus(asin=\"B00F3J4B5S\",concatenate=True))\n",
    "    apple_5s_corpus_tfidf = tfidf[apple_5s_corpus]  \n",
    "    pickle.dump(apple_5s_corpus_tfidf, open(tfidf_apple_5s_FileName, 'wb'))\n",
    "else:\n",
    "    apple_5s_corpus_tfidf = pickle.load( open( tfidf_apple_5s_FileName, \"rb\" ) )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print([(dictionary.get(tokenid),tfidf_value) for (tokenid,tfidf_value) in apple_5s_corpus_tfidf if tfidf_value >0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
