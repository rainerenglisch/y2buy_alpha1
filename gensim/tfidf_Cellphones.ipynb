{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import gzip \n",
    "def parse(path): \n",
    "    g = gzip.open(path, 'r') \n",
    "    for l in g: \n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gensim\n",
    "class MyReviews():\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        review_item_iterator = iter(parse(\"../../download/word2vec/reviews_Cell_Phones_and_Accessories_w_Cat.json.gz\"))\n",
    "        #for review_item in parse(\"../../download/reviews_Cell_Phones_and_Accessories.json.gz\"): \n",
    "        for it in range(100000):\n",
    "            if it%10000==0:\n",
    "                print(\"it=\"+str(it))\n",
    "            review_item = next(review_item_iterator)\n",
    "            #print(review_item)\n",
    "        #for review_item in self.reviews_cursor:\n",
    "\n",
    "\n",
    "            reviewText = review_item[\"reviewText\"]\n",
    "            label = review_item[\"asin\"] + \"_\" + review_item[\"reviewerID\"] \n",
    "            preprocess_reviewText = gensim.utils.simple_preprocess(reviewText)\n",
    "                  \n",
    "\n",
    "            #yield gensim.models.doc2vec.LabeledSentence(words=preprocess_reviewText, tags=[label])\n",
    "            yield preprocess_reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "def myReviews(catFilter = None, asin = None, concatenate = False):\n",
    "    preprocess_reviewText = []\n",
    "    review_item_iterator = iter(parse(\"../../download/word2vec/reviews_Cell_Phones_and_Accessories_w_Cat.json.gz\"))\n",
    "    it = 0\n",
    "    conc_count = 0\n",
    "    for review_item in review_item_iterator:\n",
    "        it += 1\n",
    "    #for it in range(1000000):\n",
    "        if it%100000==0:\n",
    "            print(\"it=\"+str(it))\n",
    "\n",
    "        reviewText = review_item[\"reviewText\"]\n",
    "        label = review_item[\"asin\"] + \"_\" + review_item[\"reviewerID\"] \n",
    "        preprocess_reviewText_i = gensim.utils.simple_preprocess(reviewText)\n",
    "\n",
    "\n",
    "        #yield gensim.models.doc2vec.LabeledSentence(words=preprocess_reviewText, tags=[label])\n",
    "        if (catFilter == None or (catFilter in review_item[\"categories\"])) and (asin == None or (asin == review_item[\"asin\"])):\n",
    "            if concatenate==False:\n",
    "                yield preprocess_reviewText_i\n",
    "            else:\n",
    "                conc_count += 1\n",
    "                preprocess_reviewText.extend(preprocess_reviewText_i)\n",
    "                print(\"Concatenated count: \"+str(conc_count))\n",
    "    if concatenate == True:\n",
    "        print(\"Return the final text with length: \"+str(len(preprocess_reviewText)))\n",
    "        print(preprocess_reviewText)\n",
    "        yield preprocess_reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it=100000\n",
      "it=200000\n",
      "it=300000\n",
      "it=400000\n",
      "it=500000\n",
      "it=600000\n",
      "it=700000\n",
      "it=800000\n",
      "it=900000\n",
      "it=1000000\n",
      "it=1100000\n",
      "it=1200000\n",
      "it=1300000\n",
      "it=1400000\n",
      "it=1500000\n",
      "it=1600000\n",
      "it=1700000\n",
      "it=1800000\n",
      "it=1900000\n",
      "it=2000000\n",
      "it=2100000\n",
      "it=2200000\n",
      "it=2300000\n",
      "it=2400000\n",
      "it=2500000\n",
      "it=2600000\n",
      "it=2700000\n",
      "it=2800000\n",
      "it=2900000\n",
      "it=3000000\n",
      "it=3100000\n",
      "it=3200000\n",
      "it=3300000\n",
      "Dictionary(128699 unique tokens: ['the', 'case', 'pictured', 'is', 'soft']...)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dictionaryFileName = '../../download/word2vec/reviews_Cell_Phones_and_Accessories_w_Cat.dict'\n",
    "if os.path.isfile(dictionaryFileName)==False:\n",
    "    #dictionary = corpora.Dictionary(myReviews(\"Cell Phones\"))\n",
    "    dictionary = corpora.Dictionary(myReviews())\n",
    "    from six import iteritems\n",
    "    once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "    dictionary.filter_tokens(once_ids)  # remove stop words and words that appear only once\n",
    "    dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "    dictionary.save(dictionaryFileName)  # store the dictionary, for future reference\n",
    "else:\n",
    "    dictionary = corpora.Dictionary.load(dictionaryFileName)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myCorpus(catFilter = None, asin = None, concatenate = False):\n",
    "    for review in myReviews(catFilter,asin,concatenate):\n",
    "    # assume there's one document per line, tokens separated by whitespace\n",
    "        yield dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tfidfFileName ='../../download/word2vec/reviews_Cell_Phones_and_Accessories_w_Cat_corpus.tfidf'\n",
    "if os.path.isfile(tfidfFileName)==False:\n",
    "    #tfidf = models.TfidfModel(myCorpus(\"Cell Phones\"))\n",
    "    tfidf = models.TfidfModel(myCorpus())\n",
    "    tfidf.save(tfidfFileName)\n",
    "else:\n",
    "    tfidf = models.TfidfModel.load(tfidfFileName)\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tfidf_apple_5s_FileName ='../../download/word2vec/apple_5s_review.tfidf'\n",
    "if os.path.isfile(tfidf_apple_5s_FileName)==False:\n",
    "    apple_5s_corpus = next(myCorpus(asin=\"B00F3J4B5S\",concatenate=True))\n",
    "    apple_5s_corpus_tfidf = tfidf[apple_5s_corpus]  \n",
    "    pickle.dump(apple_5s_corpus_tfidf, open(tfidf_apple_5s_FileName, 'wb'))\n",
    "else:\n",
    "    apple_5s_corpus_tfidf = pickle.load( open( tfidf_apple_5s_FileName, \"rb\" ) )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(dictionary.get(tokenid),tfidf_value) for (tokenid,tfidf_value) in apple_5s_corpus_tfidf if tfidf_value >0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
