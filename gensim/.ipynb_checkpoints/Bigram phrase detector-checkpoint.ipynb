{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import gzip \n",
    "#from StringIO import StringIO\n",
    "import urllib.request\n",
    "import requests, zipfile, io\n",
    "import re\n",
    "\n",
    "def parse(url): \n",
    "    if re.match(\"^http\", url):\n",
    "        r = requests.get(url)\n",
    "        g = gzip.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        g = gzip.open(url, 'r') \n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "stoplist = nltk.corpus.stopwords.words('english')\n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def myReviews(review_files_urls, catFilter = None, asin = None, concatenate = False, max_count = None, overall = None):\n",
    "    preprocess_reviewText = []\n",
    "    for url in review_files_urls:\n",
    "        print(\"Processing url: \" + url)\n",
    "        review_item_iterator = iter(parse(url))\n",
    "        it = 0\n",
    "        conc_count = 0\n",
    "        for review_item in review_item_iterator:\n",
    "            it += 1\n",
    "            if (max_count is not None) and (it > max_count):\n",
    "                return\n",
    "        #for it in range(1000000):\n",
    "            if it%100000==0:\n",
    "                print(\"it=\"+str(it))\n",
    "\n",
    "            reviewText = review_item[\"reviewText\"]\n",
    "            label = review_item[\"asin\"] + \"_\" + review_item[\"reviewerID\"] \n",
    "            preprocess_reviewText_i = gensim.utils.simple_preprocess(reviewText)\n",
    "            preprocess_reviewText_i = [lemma.lemmatize(word) for word in preprocess_reviewText_i if word not in stoplist]\n",
    "\n",
    "\n",
    "            #yield gensim.models.doc2vec.LabeledSentence(words=preprocess_reviewText, tags=[label])\n",
    "            if (catFilter == None or (catFilter in review_item[\"categories\"])) and (asin == None or (asin == review_item[\"asin\"]) and (overall == None or (overall == review_item[\"overall\"]))):\n",
    "                if concatenate==False:\n",
    "                    yield preprocess_reviewText_i\n",
    "                else:\n",
    "                    conc_count += 1\n",
    "                    preprocess_reviewText.extend(preprocess_reviewText_i)\n",
    "                    print(\"Concatenated count: \"+str(conc_count))\n",
    "    if concatenate == True:\n",
    "        print(\"Return the final text with length: \"+str(len(preprocess_reviewText)))\n",
    "        print(preprocess_reviewText)\n",
    "        yield preprocess_reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "#base_url = \"/media/mister/ntfs/Rainer/y2buy/download/amazon_reviews_96_14/\"\n",
    "base_url = \"/media/mister/Extension/dev/download/word2vec/\"\n",
    "onlyfiles = [f for f in listdir(base_url) if isfile(join(base_url, f))]\n",
    "#review_file_names = [file for file in onlyfiles if re.match(\"^review.*[^_5|_10].json.gz$\", file)]\n",
    "review_file_names = [\"reviews_Cell_Phones_and_Accessories_w_Cat.json.gz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reviews_Cell_Phones_and_Accessories_w_Cat.json.gz']\n"
     ]
    }
   ],
   "source": [
    "review_file_names= [\"reviews_Books_10.json.gz\" if file_name ==\"reviews_Books.json.gz\" else file_name for file_name in review_file_names]\n",
    "print(review_file_names)\n",
    "review_file_urls = [base_url + review_file_name for review_file_name in review_file_names]\n",
    "#print(review_file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing url: /media/mister/Extension/dev/download/word2vec/reviews_Cell_Phones_and_Accessories_w_Cat.json.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#dictionaryFileName = '../../download/word2vec/reviews_all.dict'\n",
    "bigramPhraseDetectorFileName = '../../download/word2vec/bigram.detector'\n",
    "\n",
    "if os.path.isfile(bigramPhraseDetectorFileName)==False:\n",
    "    #dictionary = corpora.Dictionary(myReviews(\"Cell Phones\"))\n",
    "    first = True\n",
    "    for review_file_url in review_file_urls:\n",
    "        myReviewsIt = myReviews([review_file_url],max_count = 1000000,catFilter=\"Cell Phones\")\n",
    "        if first:\n",
    "            bigramPhraseDetector = gensim.models.phrases.Phrases(myReviewsIt)\n",
    "            first = False\n",
    "        else:\n",
    "            bigramPhraseDetector.add_vocab(myReviewsIt)\n",
    "    print(list(bigramPhraseDetector))\n",
    "    bigramPhraseDetector.save(bigramPhraseDetectorFileName)  # store the dictionary, for future reference\n",
    "else:\n",
    "    bigramPhraseDetector = Phraser.load(bigramPhraseDetectorFileName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
