{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import gzip \n",
    "#from StringIO import StringIO\n",
    "import urllib.request\n",
    "import requests, zipfile, io\n",
    "import re\n",
    "\n",
    "def parse(url): \n",
    "    if re.match(\"^http\", url):\n",
    "        r = requests.get(url)\n",
    "        g = gzip.open(io.BytesIO(r.content))\n",
    "    else:\n",
    "        g = gzip.open(url, 'r') \n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json \n",
    "import gzip \n",
    "def parse(url): \n",
    "    g = gzip.open(url, 'r') \n",
    "    for l in g: \n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "stoplist = nltk.corpus.stopwords.words('english')\n",
    "lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def myReviews(review_files_urls, catFilter = None, asin = None, concatenate = False, max_count = None):\n",
    "    preprocess_reviewText = []\n",
    "    for url in review_files_urls:\n",
    "        print(\"Processing url: \" + url)\n",
    "        review_item_iterator = iter(parse(url))\n",
    "        it = 0\n",
    "        conc_count = 0\n",
    "        for review_item in review_item_iterator:\n",
    "            it += 1\n",
    "            if (max_count is not None) and (it > max_count):\n",
    "                return\n",
    "        #for it in range(1000000):\n",
    "            if it%100000==0:\n",
    "                print(\"it=\"+str(it))\n",
    "\n",
    "            reviewText = review_item[\"reviewText\"]\n",
    "            label = review_item[\"asin\"] + \"_\" + review_item[\"reviewerID\"] \n",
    "            preprocess_reviewText_i = gensim.utils.simple_preprocess(reviewText)\n",
    "            preprocess_reviewText_i = [lemma.lemmatize(word) for word in preprocess_reviewText_i if word not in stoplist]\n",
    "\n",
    "\n",
    "            #yield gensim.models.doc2vec.LabeledSentence(words=preprocess_reviewText, tags=[label])\n",
    "            if (catFilter == None or (catFilter in review_item[\"categories\"])) and (asin == None or (asin == review_item[\"asin\"])):\n",
    "                if concatenate==False:\n",
    "                    yield preprocess_reviewText_i\n",
    "                else:\n",
    "                    conc_count += 1\n",
    "                    preprocess_reviewText.extend(preprocess_reviewText_i)\n",
    "                    print(\"Concatenated count: \"+str(conc_count))\n",
    "    if concatenate == True:\n",
    "        print(\"Return the final text with length: \"+str(len(preprocess_reviewText)))\n",
    "        print(preprocess_reviewText)\n",
    "        yield preprocess_reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#base_url = \"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/\"\n",
    "base_url = \"/media/mister/ntfs/Rainer/y2buy/download/amazon_reviews_96_14/\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "html = urllib.request.urlopen(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/\")\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "#print(soup.prettify())\n",
    "all_html_links = soup.find_all('a')\n",
    "review_file_names = [links[\"href\"] for links in all_html_links if re.match(\"^review.*[^_5|_10].json.gz$\", links[\"href\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/mister/ntfs/Rainer/y2buy/download/amazon_reviews_96_14/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e52eb5c5fdd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/media/mister/ntfs/Rainer/y2buy/download/amazon_reviews_96_14/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0monlyfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mreview_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0monlyfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"^review.*[^_5|_10].json.gz$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/mister/ntfs/Rainer/y2buy/download/amazon_reviews_96_14/'"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "base_url = \"/media/mister/ntfs/Rainer/y2buy/download/amazon_reviews_96_14/\"\n",
    "onlyfiles = [f for f in listdir(base_url) if isfile(join(base_url, f))]\n",
    "review_file_names = [file for file in onlyfiles if re.match(\"^review.*[^_5|_10].json.gz$\", file)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for links in all_html_links:\n",
    "    if re.match(\"^review.*[^_5|_10].json.gz$\", links[\"href\"]):\n",
    "        print(links[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "review_file_names= [\"reviews_Books_10.json.gz\" if file_name ==\"reviews_Books.json.gz\" else file_name for file_name in review_file_names]\n",
    "print(review_file_names)\n",
    "review_file_urls = [base_url + review_file_name for review_file_name in review_file_names]\n",
    "#print(review_file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "import os\n",
    "dictionaryFileName = '../../download/word2vec/reviews_all.dict'\n",
    "if os.path.isfile(dictionaryFileName)==False:\n",
    "    #dictionary = corpora.Dictionary(myReviews(\"Cell Phones\"))\n",
    "    dictionary = corpora.Dictionary()\n",
    "    for review_file_url in review_file_urls:\n",
    "        dictionary.add_documents(myReviews([review_file_url],max_count = 1000000))\n",
    "        from six import iteritems\n",
    "        once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "        dictionary.filter_tokens(once_ids)  # remove stop words and words that appear only once\n",
    "        dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "        print(dictionary)\n",
    "    dictionary.save(dictionaryFileName)  # store the dictionary, for future reference\n",
    "else:\n",
    "    dictionary = corpora.Dictionary.load(dictionaryFileName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "import os\n",
    "dictionaryFileName = '../../download/word2vec/reviews_all.dict'\n",
    "if os.path.isfile(dictionaryFileName)==False:\n",
    "    #dictionary = corpora.Dictionary(myReviews(\"Cell Phones\"))\n",
    "    dictionary = corpora.Dictionary(myReviews(review_file_urls))\n",
    "    from six import iteritems\n",
    "    once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "    dictionary.filter_tokens(once_ids)  # remove stop words and words that appear only once\n",
    "    dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "    dictionary.save(dictionaryFileName)  # store the dictionary, for future reference\n",
    "else:\n",
    "    dictionary = corpora.Dictionary.load(dictionaryFileName)\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myCorpus(review_file_urls, catFilter = None, asin = None, concatenate = False, max_count = None):\n",
    "    for review in myReviews(review_file_urls,catFilter,asin,concatenate,max_count):\n",
    "    # assume there's one document per line, tokens separated by whitespace\n",
    "        yield dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=1093393, num_nnz=41632789)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tfidfFileName ='../../download/word2vec/reviews_all_corpus.tfidf'\n",
    "tfidf = models.TfidfModel.load(tfidfFileName)\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#tfidf_document_FileName ='../../download/word2vec/reviews_cell_phones_review.tfidf'\n",
    "tfidf_document_FileName ='../../download/word2vec/reviews_cell_phones.corpus'\n",
    "if os.path.isfile(tfidf_document_FileName)==False:\n",
    "    document = next(myCorpus(review_file_urls = ['../../download/word2vec/reviews_Cell_Phones_and_Accessories_w_Cat.json.gz'], catFilter=\"Cell Phones\",concatenate=True))\n",
    "    document_tfidf = tfidf[document]  \n",
    "    pickle.dump(document, open(tfidf_document_FileName, 'wb'))\n",
    "else:\n",
    "    document = pickle.load( open( tfidf_document_FileName, \"rb\" ) )\n",
    "    document_tfidf = tfidf[document]  \n",
    "    \n",
    "document_dict = dict((tokenid, count) for tokenid, count in document)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec.load('../../download/word2vec/myamazonmodel.word2vec')\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format('../../download/word2vec/GoogleNews-vectors-negative300.bin', binary=True, limit=400000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         token  term_freq     tfidf  \\\n",
      "94       phone     424902  0.836701   \n",
      "135        sim      17723  0.096396   \n",
      "114    android      21694  0.094238   \n",
      "101     screen      51072  0.089932   \n",
      "88        call      36115  0.089226   \n",
      "128       apps      22849  0.088002   \n",
      "102     mobile      20957  0.075298   \n",
      "103      nokia      15863  0.074846   \n",
      "138   unlocked      13680  0.072165   \n",
      "96     battery      48257  0.070360   \n",
      "112     iphone      21064  0.067877   \n",
      "67        text      17968  0.058434   \n",
      "27        good      63078  0.056743   \n",
      "35        like      55524  0.055823   \n",
      "106    samsung      18165  0.053266   \n",
      "58         use      59604  0.051866   \n",
      "17         one      66062  0.051633   \n",
      "2          get      52578  0.051574   \n",
      "119    service      23268  0.049913   \n",
      "93        cell      16293  0.049780   \n",
      "19        card      27391  0.049188   \n",
      "78        time      45455  0.048835   \n",
      "76         day      30518  0.048210   \n",
      "142   tracfone       7189  0.047962   \n",
      "54         new      32494  0.047362   \n",
      "12        work      58879  0.047229   \n",
      "18       great      58669  0.046412   \n",
      "85      camera      32454  0.046024   \n",
      "144    texting       7344  0.044408   \n",
      "132    verizon      10015  0.044058   \n",
      "..         ...        ...       ...   \n",
      "59         way      15076  0.022904   \n",
      "34        week      11947  0.022836   \n",
      "51     picture      14574  0.022780   \n",
      "72        last      12404  0.022637   \n",
      "74     without      14064  0.022335   \n",
      "73        send       8428  0.022222   \n",
      "26   recommend      15033  0.022133   \n",
      "131         gb       9151  0.021985   \n",
      "42         far      12805  0.021939   \n",
      "140        gsm       3743  0.021927   \n",
      "3       little      15738  0.021705   \n",
      "71         two      14394  0.021498   \n",
      "122         de       5740  0.021407   \n",
      "79      pretty      11566  0.021397   \n",
      "5          key       8320  0.021328   \n",
      "47     version       8971  0.021051   \n",
      "8          big      11088  0.021041   \n",
      "120      voice       7786  0.020893   \n",
      "110   customer       9044  0.020802   \n",
      "63       happy      11239  0.020722   \n",
      "100    working      11043  0.020716   \n",
      "49      review      13054  0.020702   \n",
      "22       think      12198  0.020616   \n",
      "45        turn      10416  0.020571   \n",
      "9       though      11443  0.020503   \n",
      "136     virgin       3736  0.020467   \n",
      "81         web       7743  0.020133   \n",
      "141     sprint       3920  0.020047   \n",
      "134         sd       7416  0.020033   \n",
      "41       money      11720  0.020021   \n",
      "\n",
      "                                           word_vector  \n",
      "94   [-1.04809, -1.02451, -0.955498, -0.361344, 0.3...  \n",
      "135  [0.594038, -1.7372, 1.23972, -1.81601, 0.34559...  \n",
      "114  [-3.92958, -0.211284, -0.239311, 4.65345, 0.07...  \n",
      "101  [-1.17817, -2.13697, 0.909865, 2.24479, 0.3716...  \n",
      "88   [-0.33118, -3.82637, 3.85393, 0.325647, 3.1811...  \n",
      "128  [-0.17236, 0.09563, 0.858206, 1.95059, -0.3707...  \n",
      "102  [-1.08778, 1.74741, 1.47753, 2.00216, 0.639684...  \n",
      "103  [-1.18261, -0.477743, -0.686531, 2.5095, -0.90...  \n",
      "138  [-3.4626, -2.06992, 1.08157, -0.139683, 0.8514...  \n",
      "96   [-4.26823, 0.74218, 1.45559, 2.85068, -2.32551...  \n",
      "112  [-2.20164, -0.346402, -1.60772, 0.869051, 0.11...  \n",
      "67   [-2.60979, -1.7846, 1.99294, 0.919722, 0.50104...  \n",
      "27   [3.45207, 0.43128, 2.50326, -0.234206, -3.9449...  \n",
      "35   [0.159903, -2.33025, 1.81971, 0.949521, -3.421...  \n",
      "106  [-3.8566, -1.78454, -0.176815, 2.77736, -1.190...  \n",
      "58   [-0.755003, -3.45269, -0.829976, -1.08235, -0....  \n",
      "17   [-0.499738, -1.30123, 1.70669, 0.794555, -0.99...  \n",
      "2    [0.238338, 1.01692, -2.55164, -0.600741, -0.27...  \n",
      "119  [-1.08432, 0.290756, 1.89266, 0.71016, 2.34464...  \n",
      "93   [-3.17013, -2.24704, 0.658841, -0.433813, 2.03...  \n",
      "19   [-1.26091, 1.49787, 3.60516, -3.56691, -0.7737...  \n",
      "78   [1.15252, 3.8653, 0.850482, -1.21998, 2.03418,...  \n",
      "76   [-2.63448, 1.58413, 3.44565, -1.52609, 1.52707...  \n",
      "142  [1.11281, 0.905984, 1.35283, 0.633139, 0.86260...  \n",
      "54   [-2.00252, -0.477597, -0.237571, -1.05435, -1....  \n",
      "12   [-1.46834, -2.53404, 0.5435, 0.00552435, -0.16...  \n",
      "18   [3.1785, -0.493588, 0.795127, 0.445252, -5.826...  \n",
      "85   [-3.06724, -3.56221, -0.840869, -1.31773, 0.06...  \n",
      "144  [-0.855729, -3.2618, 0.38341, 0.420147, -0.368...  \n",
      "132  [-0.913891, -0.0914963, 1.21329, 1.91949, 0.19...  \n",
      "..                                                 ...  \n",
      "59   [1.09655, 2.34067, 1.32868, 1.05727, 0.860894,...  \n",
      "34   [-0.657727, -2.72361, 5.17798, -2.53983, 1.502...  \n",
      "51   [-2.14236, -5.37508, 2.57883, 1.15343, 3.12582...  \n",
      "72   [1.82027, 1.24464, -2.34387, -1.06254, -3.7757...  \n",
      "74   [-2.04651, 1.59239, -0.213043, -1.08643, -0.56...  \n",
      "73   [-1.14582, 1.95854, 1.81347, -5.62824, -1.3739...  \n",
      "26   [-0.816866, 4.37367, -0.599767, -1.03328, 2.50...  \n",
      "131  [-1.36606, 0.615803, 2.27499, -0.693453, -0.77...  \n",
      "42   [3.99812, 3.29919, -2.41748, -0.222214, 3.9092...  \n",
      "140  [-2.40708, -0.921135, 0.905835, 1.57632, 0.765...  \n",
      "3    [3.8151, 0.521047, -0.994178, -0.4669, -2.4021...  \n",
      "71   [-1.89305, -1.02911, 2.80526, 1.69226, -1.9391...  \n",
      "122  [-1.02275, -0.86917, 0.754189, -0.994393, 1.08...  \n",
      "79   [2.2045, -1.09319, -2.96254, 2.35474, -2.04558...  \n",
      "5    [-1.86861, -0.996375, 0.56648, 0.130665, -2.30...  \n",
      "47   [-0.441931, -1.95254, 0.919248, 2.54386, -0.78...  \n",
      "8    [-0.975899, 3.60678, 1.46885, 1.41524, -3.4262...  \n",
      "120  [0.909813, -2.44952, 0.561241, 4.16779, 0.9278...  \n",
      "110  [4.60091, 3.30874, 1.41612, 1.28925, -1.81441,...  \n",
      "63   [1.29462, 2.96745, 2.5499, -2.33631, -0.651601...  \n",
      "100  [-0.958153, -1.63227, 0.604021, -1.9061, -0.09...  \n",
      "49   [1.09806, 0.673749, 3.81093, -0.0920787, 1.419...  \n",
      "22   [1.37429, -0.55116, 0.622018, 1.85815, -1.6529...  \n",
      "45   [1.60343, -3.95958, -1.6577, -0.523576, 0.0002...  \n",
      "9    [0.718203, 1.71977, -0.275997, 0.567979, -2.70...  \n",
      "136  [0.15766, -0.943864, 1.2793, 1.68357, 1.40181,...  \n",
      "81   [-0.683556, -1.23483, 3.36265, 0.790753, 0.434...  \n",
      "141  [-1.38218, 0.421173, 1.11293, 2.31433, 0.12571...  \n",
      "134  [1.19676, -1.24085, 0.83368, -3.01904, 2.0213,...  \n",
      "41   [1.77643, 3.02813, -0.115064, -2.59106, 2.6376...  \n",
      "\n",
      "[145 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "tbl =[[dictionary.get(tokenid), document_dict[tokenid], tfidf_value ,model.wv[dictionary.get(tokenid)] ] for (tokenid,tfidf_value) in document_tfidf if tfidf_value > 0.02 and dictionary.get(tokenid) in model.wv]\n",
    "\n",
    "df = pd.DataFrame(data=tbl,\n",
    "                  columns=[\"token\",\"term_freq\",\"tfidf\", \"word_vector\"]\n",
    "                  )\n",
    "df = df.sort_values('tfidf', ascending=False)\n",
    "df.set_index(\"token\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "nc = 5\n",
    "data = df.loc[:,\"word_vector\"]\n",
    "#print(data)\n",
    "kclusterer = KMeansClusterer(nc, distance=nltk.cluster.util.cosine_distance, avoid_empty_clusters=True) #repeats=30,\n",
    "assigned_clusters = kclusterer.cluster(data, assign_clusters=True)\n",
    "#print(assigned_clusters)\n",
    "means = np.asarray( kclusterer.means())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0480926  -1.02450836 -0.95549756 ...,  0.02163913  0.16548625\n",
      "   0.51798493]\n",
      " [ 0.59403795 -1.73720372  1.23972416 ..., -3.93258357  0.27456114\n",
      "  -2.65034246]\n",
      " [-3.92957878 -0.21128398 -0.2393105  ..., -0.05200998  2.71417689\n",
      "   0.07657263]\n",
      " ..., \n",
      " [-1.38218224  0.42117259  1.11293161 ..., -3.91186786 -1.21416354\n",
      "   0.06666767]\n",
      " [ 1.19675577 -1.240852    0.83368003 ..., -0.35842228  0.47729397\n",
      "  -2.65369177]\n",
      " [ 1.77643132  3.02813482 -0.11506433 ..., -0.07483727 -1.20956075\n",
      "  -1.77887607]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([row for row in data])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 100)\n",
      "(100,)\n",
      "<class 'numpy.ndarray'>\n",
      "[ -1.04809260e+00  -1.02450836e+00  -9.55497563e-01  -3.61343861e-01\n",
      "   3.48723322e-01   1.59822389e-01   4.31926072e-01  -1.63136780e+00\n",
      "  -4.58370447e-01   9.55533087e-01   3.45772958e+00   3.29804921e+00\n",
      "  -2.75961995e-01  -2.71984227e-02   1.34845161e+00   2.04287767e+00\n",
      "   1.04035988e-01  -2.16517615e+00   9.58454549e-01  -1.33422363e+00\n",
      "   4.47438449e-01  -1.35180056e+00   2.33614755e+00   2.74170280e-01\n",
      "  -2.70600724e+00   1.88962746e+00   3.36114454e+00  -8.23491096e-01\n",
      "  -2.79862702e-01  -2.55839992e+00  -6.57906532e+00  -1.65946972e+00\n",
      "   7.43170559e-01  -6.32300079e-01   2.72274733e+00  -2.14231992e+00\n",
      "  -2.81241715e-01   6.53607070e-01  -4.88194138e-01   9.21367586e-01\n",
      "  -3.56587195e+00   7.64054716e-01   1.94491968e-02   1.38285494e+00\n",
      "  -1.33927333e+00  -3.51533294e-01  -2.74044648e-03  -1.43408597e+00\n",
      "   1.92026818e+00  -1.63060415e+00  -1.21185648e+00  -2.97585750e+00\n",
      "  -2.47351646e+00  -1.51756132e+00  -2.63369417e+00  -5.55665493e-01\n",
      "   9.17370677e-01  -2.43759584e+00   5.80304086e-01   3.75458145e+00\n",
      "   1.76834142e+00   1.67471921e+00   1.08457029e+00  -1.15334547e+00\n",
      "  -1.70722914e+00  -1.10448277e+00   1.12665427e+00  -3.17946649e+00\n",
      "   3.51063037e+00  -3.97934131e-02   7.51535118e-01   2.29251361e+00\n",
      "  -1.38364267e+00   3.60870391e-01   1.83108377e+00   2.08736673e-01\n",
      "  -8.65932778e-02   4.96706843e-01   2.21472740e+00  -1.73439360e+00\n",
      "  -2.57488227e+00  -2.97486472e+00   1.01387906e+00  -9.49518144e-01\n",
      "   1.59313607e+00   4.00121957e-01   1.36796308e+00   6.14048362e-01\n",
      "  -7.36708999e-01  -1.51697242e+00   1.26696599e+00   9.56085920e-01\n",
      "  -9.96461570e-01  -1.45484042e+00  -2.99450326e+00   2.95414776e-01\n",
      "   3.38037515e+00   2.16391291e-02   1.65486246e-01   5.17984927e-01]\n"
     ]
    }
   ],
   "source": [
    "#print(data.shape)\n",
    "#print(data[0].shape)\n",
    "#print(type(data[0]))\n",
    "#print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "[ 0  0  0 -1  1  0  0  0  0 -1  0  0  2 -1  0  3 -1  4  0  0 -1  5  5  0  6\n",
      "  4  2 -1  0  0  0  7  0  0  8 -1  0  9  0  0 -1  0 -1  4  5  0 -1  0 -1  0\n",
      " -1  0  5 10 10 -1  0  0 -1 -1 11 -1  4  0 -1  0  0 12 11  0  2  3 -1  4 -1\n",
      " -1  2 -1  0  4  9  0  7  0 -1 -1  3 -1  0  5 12 -1 13  0  2 13 -1 -1 -1 12\n",
      "  4 -1 -1  0  4 14 -1 -1 -1 -1 -1 -1  6 -1  2 -1  5 -1 -1 -1  4 -1  0 -1  0\n",
      " -1 -1 14  8 11 -1 -1  1  0 -1 -1 -1 13  4 -1  0  0  0  0 -1]\n",
      "Estimated number of clusters: 15\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0a568297a079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Estimated number of clusters: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_clusters_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Homogeneity: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhomogeneity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completeness: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompleteness_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"V-measure: %0.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_measure_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#db = DBSCAN(eps=0.03, min_samples=10).fit(data)\n",
    "db = DBSCAN( min_samples=2, metric='cosine', algorithm='brute').fit(data) #metric=\"cosine\"\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "print(len(labels))\n",
    "print(labels)\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "#print('Estimated number of clusters: %d' % n_clusters_)\n",
    "#print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "#print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "#print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "#print(\"Adjusted Rand Index: %0.3f\"\n",
    "#      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "#print(\"Adjusted Mutual Information: %0.3f\"\n",
    "#      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "#print(\"Silhouette Coefficient: %0.3f\"\n",
    "#      % metrics.silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 5)\n",
      "         token  term_freq     tfidf  \\\n",
      "94       phone     424902  0.836701   \n",
      "135        sim      17723  0.096396   \n",
      "114    android      21694  0.094238   \n",
      "101     screen      51072  0.089932   \n",
      "88        call      36115  0.089226   \n",
      "128       apps      22849  0.088002   \n",
      "102     mobile      20957  0.075298   \n",
      "103      nokia      15863  0.074846   \n",
      "138   unlocked      13680  0.072165   \n",
      "96     battery      48257  0.070360   \n",
      "112     iphone      21064  0.067877   \n",
      "67        text      17968  0.058434   \n",
      "27        good      63078  0.056743   \n",
      "35        like      55524  0.055823   \n",
      "106    samsung      18165  0.053266   \n",
      "58         use      59604  0.051866   \n",
      "17         one      66062  0.051633   \n",
      "2          get      52578  0.051574   \n",
      "119    service      23268  0.049913   \n",
      "93        cell      16293  0.049780   \n",
      "19        card      27391  0.049188   \n",
      "78        time      45455  0.048835   \n",
      "76         day      30518  0.048210   \n",
      "142   tracfone       7189  0.047962   \n",
      "54         new      32494  0.047362   \n",
      "12        work      58879  0.047229   \n",
      "18       great      58669  0.046412   \n",
      "85      camera      32454  0.046024   \n",
      "144    texting       7344  0.044408   \n",
      "132    verizon      10015  0.044058   \n",
      "..         ...        ...       ...   \n",
      "59         way      15076  0.022904   \n",
      "34        week      11947  0.022836   \n",
      "51     picture      14574  0.022780   \n",
      "72        last      12404  0.022637   \n",
      "74     without      14064  0.022335   \n",
      "73        send       8428  0.022222   \n",
      "26   recommend      15033  0.022133   \n",
      "131         gb       9151  0.021985   \n",
      "42         far      12805  0.021939   \n",
      "140        gsm       3743  0.021927   \n",
      "3       little      15738  0.021705   \n",
      "71         two      14394  0.021498   \n",
      "122         de       5740  0.021407   \n",
      "79      pretty      11566  0.021397   \n",
      "5          key       8320  0.021328   \n",
      "47     version       8971  0.021051   \n",
      "8          big      11088  0.021041   \n",
      "120      voice       7786  0.020893   \n",
      "110   customer       9044  0.020802   \n",
      "63       happy      11239  0.020722   \n",
      "100    working      11043  0.020716   \n",
      "49      review      13054  0.020702   \n",
      "22       think      12198  0.020616   \n",
      "45        turn      10416  0.020571   \n",
      "9       though      11443  0.020503   \n",
      "136     virgin       3736  0.020467   \n",
      "81         web       7743  0.020133   \n",
      "141     sprint       3920  0.020047   \n",
      "134         sd       7416  0.020033   \n",
      "41       money      11720  0.020021   \n",
      "\n",
      "                                           word_vector  cluster  \n",
      "94   [-1.04809, -1.02451, -0.955498, -0.361344, 0.3...        0  \n",
      "135  [0.594038, -1.7372, 1.23972, -1.81601, 0.34559...        0  \n",
      "114  [-3.92958, -0.211284, -0.239311, 4.65345, 0.07...        0  \n",
      "101  [-1.17817, -2.13697, 0.909865, 2.24479, 0.3716...       -1  \n",
      "88   [-0.33118, -3.82637, 3.85393, 0.325647, 3.1811...        1  \n",
      "128  [-0.17236, 0.09563, 0.858206, 1.95059, -0.3707...        0  \n",
      "102  [-1.08778, 1.74741, 1.47753, 2.00216, 0.639684...        0  \n",
      "103  [-1.18261, -0.477743, -0.686531, 2.5095, -0.90...        0  \n",
      "138  [-3.4626, -2.06992, 1.08157, -0.139683, 0.8514...        0  \n",
      "96   [-4.26823, 0.74218, 1.45559, 2.85068, -2.32551...       -1  \n",
      "112  [-2.20164, -0.346402, -1.60772, 0.869051, 0.11...        0  \n",
      "67   [-2.60979, -1.7846, 1.99294, 0.919722, 0.50104...        0  \n",
      "27   [3.45207, 0.43128, 2.50326, -0.234206, -3.9449...        2  \n",
      "35   [0.159903, -2.33025, 1.81971, 0.949521, -3.421...       -1  \n",
      "106  [-3.8566, -1.78454, -0.176815, 2.77736, -1.190...        0  \n",
      "58   [-0.755003, -3.45269, -0.829976, -1.08235, -0....        3  \n",
      "17   [-0.499738, -1.30123, 1.70669, 0.794555, -0.99...       -1  \n",
      "2    [0.238338, 1.01692, -2.55164, -0.600741, -0.27...        4  \n",
      "119  [-1.08432, 0.290756, 1.89266, 0.71016, 2.34464...        0  \n",
      "93   [-3.17013, -2.24704, 0.658841, -0.433813, 2.03...        0  \n",
      "19   [-1.26091, 1.49787, 3.60516, -3.56691, -0.7737...       -1  \n",
      "78   [1.15252, 3.8653, 0.850482, -1.21998, 2.03418,...        5  \n",
      "76   [-2.63448, 1.58413, 3.44565, -1.52609, 1.52707...        5  \n",
      "142  [1.11281, 0.905984, 1.35283, 0.633139, 0.86260...        0  \n",
      "54   [-2.00252, -0.477597, -0.237571, -1.05435, -1....        6  \n",
      "12   [-1.46834, -2.53404, 0.5435, 0.00552435, -0.16...        4  \n",
      "18   [3.1785, -0.493588, 0.795127, 0.445252, -5.826...        2  \n",
      "85   [-3.06724, -3.56221, -0.840869, -1.31773, 0.06...       -1  \n",
      "144  [-0.855729, -3.2618, 0.38341, 0.420147, -0.368...        0  \n",
      "132  [-0.913891, -0.0914963, 1.21329, 1.91949, 0.19...        0  \n",
      "..                                                 ...      ...  \n",
      "59   [1.09655, 2.34067, 1.32868, 1.05727, 0.860894,...       -1  \n",
      "34   [-0.657727, -2.72361, 5.17798, -2.53983, 1.502...        5  \n",
      "51   [-2.14236, -5.37508, 2.57883, 1.15343, 3.12582...       -1  \n",
      "72   [1.82027, 1.24464, -2.34387, -1.06254, -3.7757...       -1  \n",
      "74   [-2.04651, 1.59239, -0.213043, -1.08643, -0.56...       -1  \n",
      "73   [-1.14582, 1.95854, 1.81347, -5.62824, -1.3739...        4  \n",
      "26   [-0.816866, 4.37367, -0.599767, -1.03328, 2.50...       -1  \n",
      "131  [-1.36606, 0.615803, 2.27499, -0.693453, -0.77...        0  \n",
      "42   [3.99812, 3.29919, -2.41748, -0.222214, 3.9092...       -1  \n",
      "140  [-2.40708, -0.921135, 0.905835, 1.57632, 0.765...        0  \n",
      "3    [3.8151, 0.521047, -0.994178, -0.4669, -2.4021...       -1  \n",
      "71   [-1.89305, -1.02911, 2.80526, 1.69226, -1.9391...       -1  \n",
      "122  [-1.02275, -0.86917, 0.754189, -0.994393, 1.08...       14  \n",
      "79   [2.2045, -1.09319, -2.96254, 2.35474, -2.04558...        8  \n",
      "5    [-1.86861, -0.996375, 0.56648, 0.130665, -2.30...       11  \n",
      "47   [-0.441931, -1.95254, 0.919248, 2.54386, -0.78...       -1  \n",
      "8    [-0.975899, 3.60678, 1.46885, 1.41524, -3.4262...       -1  \n",
      "120  [0.909813, -2.44952, 0.561241, 4.16779, 0.9278...        1  \n",
      "110  [4.60091, 3.30874, 1.41612, 1.28925, -1.81441,...        0  \n",
      "63   [1.29462, 2.96745, 2.5499, -2.33631, -0.651601...       -1  \n",
      "100  [-0.958153, -1.63227, 0.604021, -1.9061, -0.09...       -1  \n",
      "49   [1.09806, 0.673749, 3.81093, -0.0920787, 1.419...       -1  \n",
      "22   [1.37429, -0.55116, 0.622018, 1.85815, -1.6529...       13  \n",
      "45   [1.60343, -3.95958, -1.6577, -0.523576, 0.0002...        4  \n",
      "9    [0.718203, 1.71977, -0.275997, 0.567979, -2.70...       -1  \n",
      "136  [0.15766, -0.943864, 1.2793, 1.68357, 1.40181,...        0  \n",
      "81   [-0.683556, -1.23483, 3.36265, 0.790753, 0.434...        0  \n",
      "141  [-1.38218, 0.421173, 1.11293, 2.31433, 0.12571...        0  \n",
      "134  [1.19676, -1.24085, 0.83368, -3.01904, 2.0213,...        0  \n",
      "41   [1.77643, 3.02813, -0.115064, -2.59106, 2.6376...       -1  \n",
      "\n",
      "[145 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"cluster\"] = pd.Series(labels, index=df.index)\n",
    "\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"centroid\"] = pd.Series( means[assigned_clusters].tolist(), index=df.index)\n",
    "\n",
    "print(df.shape)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"centroid_distance\"] = df.apply(lambda row:nltk.cluster.util.cosine_distance(row['word_vector'], row['centroid']), axis=1)\n",
    "\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('clustered_smartphone_features.xlsx')\n",
    "df.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
